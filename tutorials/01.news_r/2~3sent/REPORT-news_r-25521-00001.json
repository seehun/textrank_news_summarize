{
	"Meta(Acqusition)": {
		"doc_id": "REPORT-news_r-25521",
		"doc_category": "REPORT",
		"doc_type": "news_r",
		"doc_name": "[트랜D]인간의 '편견', AI로 잡아낼 수 있다. ",
		"author": "김지하",
		"publisher": "중앙일보",
		"publisher_year": "2020",
		"doc_origin": "중앙일보"
	},
	"Meta(Refine)": {
		"passage_id": "REPORT-news_r-25521-00001",
		"passage": "인공지능의 능력을 맹신해선 안 된다는 경고가 이어지고 있다.\n  특히 인간의 편견이 기계가 학습하는 데이터에 스며들어, 인간이 하는 것과 같은 오판을 기계도 그대로 내보낼 수 있다는 주장이 지속해서 나오고 있다.\n  기계는 결국 사람의 잣대로 나뉜 카테고리를 있는 그대로 학습하기 때문에, 마냥 객관적일 수만은 없다는 것이다.\n  하지만 기계의 눈은 사람의 눈과 다르다.\n  오히려 기계가 사람의 시선을 역으로 판단해 낼 수도 있다.\n  사람으로선 ‘둘이 뭐가 달라?’라는 생각이 들 법한 카테고리 사이에서, 기계는 미묘한 차이를 잡아낼 수 있다.\n  예를 들어 사람은 생각보다 어린아이·동물이 흩뿌린 그림과 전문 화가의 추상화를 잘 구분해내지 못한다.\n  하지만 한 연구에서는 딥러닝 알고리즘이 사람보다 높은 확률로 둘을 구분해 냈다고 밝혔다.\n  그뿐만 아니라 연구진은 사람들이 그림을 구별할 때 스스로 생각하는 것보다 훨씬 더 작품의 의도를 잘 파악하고 있다는 점 또한 기계적으로 도출해 냈다.\n AI로 밝혀내는 ‘사람의 편견’사람 자신도 몰랐던 ‘치우친 생각’을 기계의 눈을 통해 확인할 수 있다는 주장 또한 AI 바이어스 연구의 한쪽에서 지속해서 이어지고 있다.\n  지난 7월 미국 코넬대 연구진은, 인간의 의사결정 과정에서 알고리즘이 차별 탐지자로서의 역할을 해낼 수 있을 것이라는 내용의 논문을 냈다(Kleinberg et al.\n , 2020).\n  예를 들어 기업에서의 과거 채용 기록을 기반으로 모델을 만들면, 암묵적으로 자행 됐던 차별이 통계적으로 드러나게 되고, 따라서 이 알고리즘을 채용 심사 과정에 ‘넛지’를 주듯 활용할 수 있다고 연구진은 주장했다.\n  기계를 활용함으로써 단순히 차별의 발생을 탐지만 하는 데 그치지 않고 예방까지 해낼 것이라는 전망도 함께 제시됐다.\n  필자 또한 2017년 석사 학위 논문을 통해 미디어 사진이 내포할 수 있는 편향을 검토한 바 있다.\n  유럽에서 발생한 테러리즘과 시리아에서 벌어진 내전에 대해 서구 통신사인 로이터와 아랍계 통신사인 알자지라가 실어나른 사진들을 살펴봤다.\n  몇만 장의 데이터를 다루기 위해 인공지능의 감정 분석과 객체 탐지, 그리고 각 요소의 사진 속 위치를 총괄적으로 분석했다.\n  기계 분석 결과 시리아 사태에 대해 중동 미디어는 좀 더 구체적인 상황 묘사 및 팩트 전달에 가까운 사물을 사진에 배치했지만, 서구는 인물의 슬픔이 극대화된 모습을 이미지 중앙부에 배치했다.\n ",
		"passage_Cnt": 1211
	},
	"Annotation": {
		"summary1": "인간의 편견이 기계가 학습하는 데이터에 스며들어 인간이 하는 것과 같은 오판을 기계도 그대로 내보낼 수 있기 때문에 인공지능의 능력을 맹신해서는 안 된다는 경고가 이어지고 있다.",
		"summary2": "인공지능의 능력을 맹신해선 안 된다는 경고가 이어지고 있다. 특히 인간의 편견이 기계가 학습하는 데이터에 스며들어, 인간이 하는 것과 같은 오판을 기계도 그대로 내보낼 수 있다는 주장이 지속해서 나오고 있다.",
		"summary3": null,
		"summary_3_cnt": null
	}
}
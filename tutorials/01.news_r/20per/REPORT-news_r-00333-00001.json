{
	"Meta(Acqusition)": {
		"doc_id": "REPORT-news_r-00333",
		"doc_category": "REPORT",
		"doc_type": "news_r",
		"doc_name": "[고학수의 미래를 묻다] 인공지능은 차별·편견을 인간에게서 배운다",
		"author": "김선영",
		"publisher": "중앙일보",
		"publisher_year": "2020",
		"doc_origin": "중앙일보"
	},
	"Meta(Refine)": {
		"passage_id": "REPORT-news_r-00333-00001",
		"passage": "AI가 그리는 유토피아와 디스토피아프로기사 이세돌과 세기의 대결을 벌인 알파고와 한돌 만이 아니다.\n  알게 모르게 인공지능(AI)은 우리 일상생활 깊숙이 들어와 있다.\n  검색자의 성향과 위치를 파악해 맞춤형 결과를 보여주는 인터넷 검색 뒤에도 인공지능이 숨어 있다.\n  스팸 메일을 걸러내고, 휴대전화 메시지를 작성할 때 맥락을 알아차려 적당한 단어와 표현을 추천하는 자동완성 기능도 인공지능이다.\n  산업 현장에서도 활용 범위가 넓어지고 있다.\n  대출 등과 관련한 금융권의 신용평가와 채용 등에서도 실용화하고 있다.\n  이런 모습만 보면 인공지능이 구현하는 유토피아가 성큼 다가온 것 같다.\n  그러나 방심은 금물이다.\n  정반대로 디스토피아를 우려하지 않을 수 없다.\n  영화 속에 그려지는, 인공지능에 의한 극단의 감시사회 같은 것에 대한 걱정이다.\n  인공지능이 잘못된 판단, 편향과 편견이 담긴 판단을 한다는 보도는 이런 불안감을 부추기고 있다.\n  지난해 말에는 안면 인식 인공지능의 문제를 지적한 보고서가 나왔다.\n  ‘일부 안면 인식 프로그램은 아시아·아프리카계를 잘못 알아볼 확률이 백인 남성을 잘못 알아볼 확률의 100배에 이른다’는 것이었다.\n  미국 표준기술연구소(NIST)가 200개 가까운 안면 인식 알고리즘을 분석한 결과다.\n  이런 안면 인식을 실생활에 도입하면 어떤 일이 벌어질까.\n  미국에 도착한 당신을 인공지능이 위험인물로 착각해 공항에서 경보음이 ‘삐비빅~’ 울릴 수 있다.\n  유독 아시아·아프리카계에 대해서만 이런 오류가 반복될 것이다.\n  인종차별이란 의심이 싹트지 않을까.\n  아마존, 인공지능 채용 폐기 노골적으로 성차별했다는 논란이 불거진 인공지능도 있었다.\n  아마존이 결국 폐기한 인공지능 채용 프로그램이다.\n  성별을 따로 적지 않아도 여대를 졸업했다든지 경력에 여성 스포츠동아리 이름 등이 들어가면 채용 추천에서 배제했다.\n  왜 그랬을까.\n  그전까지 아마존에 여성 지원자가 별로 없었고, 그중에 성과를 평가받아 임원으로 승진한 여성은 더 드물었기에, 이런 데이터를 보고 배운 인공지능이 남성을 먼저 추천한 것으로 짐작된다.\n  과거 데이터에서 성차별을 배운 것이다.\n  흔히 ‘사내들만 득시글거린다(sea of dudes)’라고 표현하는 미국 정보기술(IT) 업계의 현실이 반영된 일면으로 보인다.\n  신용카드 발급도 비슷하다.\n  연봉과 금융거래 실적이 비슷한 30대 남녀가 있다고 하자.\n ",
		"passage_Cnt": 1208
	},
	"Annotation": {
		"summary1": "인공지능이 금융권, 인터넷 검색, 산업 현장 등의 우리 일상에 깊숙이 들어와 있는 만큼 디스토피아를 우려하지 않을 수 없다. ",
		"summary2": null,
		"summary3": "알게 모르게 인공지능(AI)은 우리 일상생활 깊숙이 들어와 있다. 검색자의 성향과 위치를 파악해 맞춤형 결과를 보여주는 인터넷 검색 뒤에도 인공지능이 숨어 있다. 산업 현장에서도 활용 범위가 넓어지고 있다. 대출 등과 관련한 금융권의 신용평가와 채용 등에서도 실용화하고 있다. 정반대로 디스토피아를 우려하지 않을 수 없다.",
		"summary_3_cnt": 184
	}
}
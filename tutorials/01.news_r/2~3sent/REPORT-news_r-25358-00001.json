{
	"Meta(Acqusition)": {
		"doc_id": "REPORT-news_r-25358",
		"doc_category": "REPORT",
		"doc_type": "news_r",
		"doc_name": "[양성희의 시시각각] 알고리즘이 만드는 세상",
		"author": "김선영",
		"publisher": "중앙일보",
		"publisher_year": "2020",
		"doc_origin": "중앙일보"
	},
	"Meta(Refine)": {
		"passage_id": "REPORT-news_r-25358-00001",
		"passage": "“유튜브의 알 수 없는 알고리즘에 이끌려 여기까지 오게 됐다.\n ” 유튜브에서 자주 보이는 댓글이다.\n  ‘자동 재생’ 기능으로 끝없이 이어지는 추천 영상을 보다 보면 10분 같은 1시간이 후딱 지난다.\n  입맛에 맞는 영상을 맞춤하게 골라주니 유용하지만, 한편으론 찜찜하다.\n  유튜브의 최고 상품 담당자(CPO) 닐 모한은 지난해 뉴욕타임스와의 인터뷰에서 “유튜브 시청시간 70%가 추천 알고리즘에 의한 결과며, 알고리즘 도입으로 총 비디오 시청시간이 20배 이상 증가했다”고 밝혔다.\n  넷플릭스도 “매출의 75%가 추천 시스템에 의해 발생한다”고 밝혔다.\n  알지 못하는 사이에 추천 알고리즘에 포박당했다는 얘기다.\n  기술과 데이터를 독점한 거대 기업들이 개발한 알고리즘은 ‘영업기밀’이라 정체를 알 길이 없다.\n  트위터는 최근 자동 이미지 크롭(잘라내기) 알고리즘이 인종차별적이라는 비판을 받고 사과했다.\n  흑인과 백인 얼굴을 같이 올린 게시물의 이미지 미리보기에서 백인 얼굴을 우선해 보여주는 게 문제였다.\n  2015년 구글의 사진 앱도 흑인 남성 두 명을 고릴라로 인식해 논란이 됐다.\n  안면 인식 소프트웨어가 백인보다 아시아인이나 아프리카계 미국인에서 오류가 많다는 것도 알려진 얘기다.\n  알고리즘의 기반인 데이터 수집에서의 편향성 때문이다.\n  알고리즘 개발자(주로 남성, 백인)들의 편향성도 작용한다.\n  인공지능(AI) 스피커들은 대부분 젊은 여성의 목소리다.\n  보조적인 ‘여비서’ 이미지로 성차별을 강화한다.\n  유튜브 추천 알고리즘은 분열과 극단화를 조장한다는 비판도 받는다.\n  책 『노모포비아, 스마트폰이 없는 공포』에 따르면 “추천 동영상은 본인이 직접 검색한 첫 동영상보다 늘 과격하다.\n ” 조깅을 검색하면 울트라 마라톤이 추천되고 채식주의로 시작하면 비건(엄격한 채식주의자)으로 이어지는 식이다.\n  정치 이슈라면 더 심각하다.\n  미국에서 트럼프를 검색하면 순식간에 홀로코스트를 부정하거나 백인우월주의를 옹호하는 동영상으로 넘어간다.\n  반대로 힐러리 클린턴 동영상으로 시작하면 미 정부가 9·11의 배후라는 식의 좌파 음모론으로 이어진다.\n  유튜브에 가짜뉴스와 극단주의가 출몰하는 이유다.\n  배경에는 이용자를 더 오래 화면 앞에 잡아둬 수익을 극대화하려는 경제적 동기가 있다.\n  “학습하는 기계가 하는 일은 오직 유튜브 이용자들의 사용시간을 극대화하는 것뿐”(『노모포비아』), 과격하고 극단적인 내용일수록 사람들을 붙잡을 수 있기에 자동으로 그런 동영상을 추천한다는 설명이다.\n ",
		"passage_Cnt": 1251
	},
	"Annotation": {
		"summary1": "안면 인식 소프트웨어가 백인보다 아시아인이나 아프리카계 미국인에서 오류가 많이 나는데 데이터 수집에서의 편향성과 개발자들의 편향성이 작용하기 때문이다.",
		"summary2": "안면 인식 소프트웨어가 백인보다 아시아인이나 아프리카계 미국인에서 오류가 많다는 것도 알려진 얘기다. 알고리즘의 기반인 데이터 수집에서의 편향성 때문이다. 알고리즘 개발자(주로 남성, 백인)들의 편향성도 작용한다.",
		"summary3": null,
		"summary_3_cnt": null
	}
}
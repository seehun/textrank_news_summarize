{
	"Meta(Acqusition)": {
		"doc_id": "REPORT-news_r-06050",
		"doc_category": "REPORT",
		"doc_type": "news_r",
		"doc_name": "AI 윤리의 대모 \"사람은 AI를 만들고, AI는 사람을 만든다\"",
		"author": "김정민",
		"publisher": "중앙일보",
		"publisher_year": "2020",
		"doc_origin": "중앙일보"
	},
	"Meta(Refine)": {
		"passage_id": "REPORT-news_r-06050-00001",
		"passage": "\"검색 엔진에 흑인 소녀를 검색했을 때 '죽이는(hot)', '달콤한(sugary)'이 나오는 결과에 대해 물어야 한다.\n  이것이 최선인가?\" (책 『구글은 어떻게 여성을 차별하는가(Algorithms of Oppression)』) 아마존은 2018년 인공지능(AI) 채용 시스템을 폐기했다.\n  AI가 여성을 차별했기 때문이다.\n  미국 표준기술연구소(NIST)는 지난해 \"많은 얼굴 인식 시스템의 아시아·아프리카인 인식률이 백인보다 10~100배 떨어진다\"는 보고서를 냈다.\n   AI를 활용한 기술이 넘쳐나는 세상이지만 AI의 과도한 활용을 걱정하는 목소리도 동시에 커지고 있다.\n  AI 학습 데이터에 인간의 편견이 반영되는 사례가 속속 공개되고 있어서다.\n  AI의 윤리적 결함을 보완하려면 어떻게 해야할까.\n  AI '윤리 선생님'을 자처하는 프란체스카 로시(Francesca Rossi) IBM AI 윤리 글로벌 총괄을 지난달 20일 서울 여의도 한국 IBM 본사에서 화상 인터뷰했다.\n  그는 유럽위원회(EC) 인공지능 고위 전문가 그룹 멤버기도 하다.\n  AI 윤리란 무엇인가.\n 사람에게 기대하는 특성을 AI가 갖추도록 하는 것이다.\n  AI는 결국 사람이 더 나은 결정을 하도록 돕는 기계다.\n  그만큼 신뢰할 수 있어야 한다.\n  IBM 원칙상 신뢰하기 위해선 4개의 기준을 충족해야 한다.\n   4개 기준을 말해달라.\n ▶공정성(Fairness) ▶설명 가능성(Explain ability) ▶견고성(Robustness) ▶투명성(Transparency)이다.\n  공정성은 서로 다른 집단을 차별하지 않는 '편견 없는 알고리즘'이다.\n  설명 가능성은 AI가 왜 이런 결정을 내렸는지 설명할 수 있어야 한다는 것이다.\n  예컨대 AI가 의사에게 특정 치료법을 추천했다면, 왜 이 치료법을 골랐는지 인간이 알 수 있어야 한다.\n  견고성은 오류에 대처하는 능력이다.\n  AI는 학습한 것은 잘 알지만, 아주 작은 차이에도 큰 오차를 내는 기계다.\n  마지막은 투명성이다.\n  어떻게 데이터를 모으고 교육했는지, 개발자와 디자이너의 결정이 어땠는지 공개해야 한다는 것이다.\n   AI의 설명을 받아들이지 못한다면.\n 듣는 사람에 맞춰 설명할 수 있어야 진정한 설명 가능성이다.\n  의사가 아닌 개발자나 규제 당국이 AI에게 '왜 이 치료법을 추천했냐'고 물어도 대답할 수 있어야 한다.\n  AI는 독립지능이나 대안지능이 아니다.\n ",
		"passage_Cnt": 1205
	},
	"Annotation": {
		"summary1": "AI 학습 데이터에 윤리적 결함의 사례가 속속히 공개되며 과도한 AI의 과도한 활용에 대한 우려의 목소리가 커지고 있다.",
		"summary2": "AI를 활용한 기술이 넘쳐나는 세상이지만 AI의 과도한 활용을 걱정하는 목소리도 동시에 커지고 있다. AI 학습 데이터에 인간의 편견이 반영되는 사례가 속속 공개되고 있어서다. AI의 윤리적 결함을 보완하려면 어떻게 해야할까.",
		"summary3": null,
		"summary_3_cnt": null
	}
}
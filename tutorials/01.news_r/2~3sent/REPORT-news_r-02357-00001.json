{
	"Meta(Acqusition)": {
		"doc_id": "REPORT-news_r-02357",
		"doc_category": "REPORT",
		"doc_type": "news_r",
		"doc_name": "[김병필의 인공지능 개척시대] 인공지능 연구자들이 바르셀로나에 모인 이유",
		"author": "김선영",
		"publisher": "중앙일보",
		"publisher_year": "2020",
		"doc_origin": "중앙일보"
	},
	"Meta(Refine)": {
		"passage_id": "REPORT-news_r-02357-00001",
		"passage": "필자는 지난 27일부터 스페인 바르셀로나에서 열리고 있는 인공지능 공정성 국제 학술대회에 참석하고 있다.\n  미국 컴퓨터 협회(ACM)의 후원을 받는 이공계 분야 행사인데도 세계 각국의 법률가·철학자·윤리학자·정책전문가들이 다수 참여하고 있다.\n  정식 명칭은 ‘인공지능 공정성·책임성·투명성에 관한 국제 학술대회’다.\n  2018년부터 시작된 신생 학회임에도 벌써 수백 명에 이르는 인공지능 연구자들이 참가하여 성황리에 진행되고 있다.\n  그만큼 인공지능 공정성에 대한 세계적 관심이 뜨겁다는 뜻이다.\n  이렇게 많은 이들이 인공지능의 공정성에 관심을 두는 이유는 무엇일까? 어떠한 제품이든지 연구개발 단계를 넘어 고객을 위한 제품으로 출시되면 예상치 못했던 여러 문제가 발견되게 마련이다.\n  인공지능 서비스도 예외는 아니다.\n  구글의 사진 인식 서비스는 한 흑인 여성의 얼굴을 “고릴라”라고 잘못 인식하는 바람에 급히 프로그램을 수정해야 했다.\n  흑인 여성에 대한 학습 데이터가 부족하여 인식 정확도가 낮았던 까닭이다.\n  마이크로소프트사가 2016년 내놓은 인공지능 채팅 프로그램은 출시 직후부터 인터넷 사용자들에게 인종차별적이고 폭력적인 표현을 학습하게 하는 문제가 발생했다.\n  결국 출시 하루 만에 서비스가 중단되고 말았다.\n  구글 번역 서비스에서도 문제점이 지적되곤 한다.\n  특히 터키어 오역 사례가 유명하다.\n  터키어는 3인칭 대명사에 성별 구분이 없다.\n  그래서 터키어로 “그는 의사다”라고 하면 그 사람이 남성일 수도, 여성일 수도 있다.\n  그런데도 구글 번역기는 이 터키어 문장을 “그 남자는 의사다(he is a doctor)”라고 번역했다.\n  언어 간 성별 차이를 고려하지 않은 잘못된 번역이다.\n     그뿐만 아니라 “그는 간호사다”라는 터키어 문장은 “그 여자는 간호사다(she is a nurse)”라고 잘못 번역됐다.\n  구글 번역 서비스가 데이터를 학습하면서 우리 사회의 차별적 문화까지 받아들여 잘못 학습한 결과다.\n  우리는 TV를 샀는데 화면이 잘 나오지 않으면 제품에 하자가 있다고 생각한다.\n  반드시 하자에 이르지 않는다고 하더라도 품질이 낮은 제품은 시장에서 외면받고 도태되게 마련이다.\n  인공지능의 경우에는 공정성이라는 성능을 충분히 갖추지 못하면, 고객의 선택을 받기 어렵다.\n  얼굴 인식 인공지능이 특정 인종이나 성별의 얼굴을 제대로 인식하지 못한다거나, 번역 인공지능이 언어 간 성별 차이를 제대로 고려하지 못한다면, 적정한 품질을 갖추지 못한 것이다.\n ",
		"passage_Cnt": 1248
	},
	"Annotation": {
		"summary1": "인공지는 공정성, 책임성, 투명성에 관한 국제 학술대회에 세계 각국의 법률가, 철학자, 윤리학자, 정책전문가들이 가수 참여하여 신생 학회임에도 성황리에 진행되고 있다.",
		"summary2": "미국 컴퓨터 협회(ACM)의 후원을 받는 이공계 분야 행사인데도 세계 각국의 법률가·철학자·윤리학자·정책전문가들이 다수 참여하고 있다. 정식 명칭은 ‘인공지능 공정성·책임성·투명성에 관한 국제 학술대회’다. 2018년부터 시작된 신생 학회임에도 벌써 수백 명에 이르는 인공지능 연구자들이 참가하여 성황리에 진행되고 있다.",
		"summary3": null,
		"summary_3_cnt": null
	}
}